{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ee29838-dd50-495f-bf03-e1e54d1a0e88",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f57770-d71a-4e6a-a6e4-96ff18108a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the pytorch library into environment and check its version\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "print(\"Using torch\", torch.__version__)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5f1a7b-34de-4468-a8b9-aab7f4697f2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.1+cu118.html\n",
    "!pip install git+https://github.com/pyg-team/pytorch_geometric.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3d259a-0fdf-4ee7-b897-80a693917485",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d96105-4ff1-4489-9229-8a13b19846d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data, NeighborSampler\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.utils import to_networkx\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c889fc-4646-4d01-82c7-36b8f99086bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Metadata Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce41849-43c3-437a-bedc-1ddfd0b3f8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metadata of items\n",
    "file_path = \"metadata.txt\"\n",
    "with open(file_path, 'r') as file:\n",
    "    metadata = [line.strip() for line in file.readlines() if line.strip()]\n",
    "len(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51172216-d357-4834-863f-8083ff60f464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map org_id to new_id\n",
    "import csv\n",
    "file_path = 'item_list.txt'\n",
    "org_remap_dict = {}\n",
    "with open(file_path, 'r') as file:\n",
    "    next(file)\n",
    "    for line in file:\n",
    "        org_id, remap_id = line.strip().split()\n",
    "        org_remap_dict[org_id] = int(remap_id)\n",
    "len(org_remap_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29feb23-fadd-4ecc-9e0a-c59c9658407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = {}\n",
    "titles = {}\n",
    "prices = {}\n",
    "for line in metadata:\n",
    "    item_id = re.search(r\"'asin'\\s*:\\s*'([^']+)'\", line).group(1)\n",
    "    new_id = org_remap_dict[item_id]\n",
    "    price = re.search(r\"'price': (\\d+\\.\\d+)\", line)\n",
    "    if price:\n",
    "        price = float(price.group(1))\n",
    "        prices[new_id] = price\n",
    "    title = re.search(r\"'title': '([^']*)'\", line)\n",
    "    if title:\n",
    "        title = title.group(1)\n",
    "        if len(title) > 300:\n",
    "            title = title[0:300]  \n",
    "        titles[new_id] = title\n",
    "    descrip_pos = line.find(\"'description':\")\n",
    "    title_pos = line.find(\"'title':\")\n",
    "    if descrip_pos != -1 and title_pos != -1:\n",
    "        description = line[descrip_pos + len(\"'description':\"):title_pos].strip()\n",
    "        if len(description) > 300:\n",
    "            description = description[0:300]\n",
    "        descriptions[new_id] = description\n",
    "print(len(descriptions))\n",
    "print(len(titles))\n",
    "print(len(prices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfd3371-3ae5-4065-9515-02b58f25b612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "embed_descriptions = {}\n",
    "for key, sentence in descriptions.items():\n",
    "    if len(sentence) > 200:\n",
    "        small = sentence[0:200]\n",
    "    inputs = tokenizer(small, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "    embed_descriptions[key] = cls_embedding.detach().tolist()\n",
    "\n",
    "# with open('descriptions.pkl', 'wb') as file:\n",
    "#     pickle.dump(embed_descriptions, file)\n",
    "\n",
    "embed_titles = {}\n",
    "for key, sentence in titles.items():\n",
    "    if len(sentence) > 200:\n",
    "        small = sentence[0:200]    \n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "    embed_titles[key] = cls_embedding.detach().tolist()\n",
    "\n",
    "# with open('titles.pkl', 'wb') as file:\n",
    "#     pickle.dump(embed_titles, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a342af90-af50-4a1d-ab71-b358ffd1c652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_path = 'descriptions.pkl'\n",
    "with open(file_path, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "file_path2 = 'titles.pkl'\n",
    "with open(file_path2, 'rb') as file2:\n",
    "    data2 = pickle.load(file2)\n",
    "embed_descriptions = data\n",
    "embed_titles = data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236cf30b-3eb7-41b2-a5b6-b29ab19f6a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets mean value of each feature\n",
    "from statistics import mean\n",
    "mean_value = mean(prices.values())\n",
    "descrip_array = np.array(list(embed_descriptions.values()))\n",
    "title_array = np.array(list(embed_titles.values()))\n",
    "mean_descrip = np.mean(descrip_array, axis = 0)\n",
    "mean_title = np.mean(title_array, axis = 0)\n",
    "mean_price = np.array([mean_value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22e7bd5-5f19-481a-8f43-cf1d1cc6de02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets features for each node\n",
    "mean_price_tensor = torch.tensor(np.tile(mean_price, (91599, 1)))\n",
    "mean_title_tensor = torch.tensor(np.tile(mean_title, (91599, 1)))\n",
    "mean_descrip_tensor = torch.tensor(np.tile(mean_descrip, (91599, 1)))\n",
    "for index, value in embed_titles.items():\n",
    "    mean_title_tensor[index] = torch.tensor(value)\n",
    "for index, value in embed_descriptions.items():\n",
    "    mean_descrip_tensor[index] = torch.tensor(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed50afd8-7b2a-474d-ae59-c746215545b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIAL NODE EMBEDDING\n",
    "X = torch.cat((mean_title_tensor, mean_descrip_tensor, mean_price_tensor), dim=1)\n",
    "# torch.save(X, 'X.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d224f0e5-fb3f-4453-a95a-b9247b86a064",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Training Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03e2b9f-8ae9-4d95-9fa5-50d72f7a2260",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_train_edge_index = []\n",
    "item_train_edge_source = []\n",
    "item_train_edge_target = []\n",
    "seen_edges = set()\n",
    "\n",
    "file_path = 'train.txt'\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        values = list(map(int, line.strip().split()))\n",
    "        user = values[0]\n",
    "        items = values[1:]\n",
    "        user_edges = [(user, item) for item in items]\n",
    "        # for i, item1 in enumerate(items):\n",
    "        #     for item2 in items[i+1:]:\n",
    "        #         if item1 < item2:\n",
    "        #             if (item1,item2) not in seen_edges:\n",
    "        #                 seen_edges.add((item1,item2))\n",
    "        #                 item_train_edge_source.append(item1)\n",
    "        #                 item_train_edge_target.append(item2)\n",
    "        #         else:\n",
    "        #             if (item2,item1) not in seen_edges:\n",
    "        #                 seen_edges.add((item2,item1))\n",
    "        #                 item_train_edge_source.append(item2)\n",
    "        #                 item_train_edge_target.append(item1)\n",
    "        user_train_edge_index.extend(user_edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ff16c8-a683-405e-895b-3edfe5b0d280",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_train_edge_index_np = np.array(user_train_edge_index, dtype=np.int64).T\n",
    "user_train_edge_index = torch.tensor(user_train_edge_index_np, dtype=torch.long).contiguous()\n",
    "torch.save(user_train_edge_index, 'user_train_edge_index.pt')\n",
    "\n",
    "# item_train_edge_index = torch.tensor([item_train_edge_source, item_train_edge_target], dtype=torch.long)\n",
    "\n",
    "# torch.save(item_train_edge_index, 'item_train_edges.pt')\n",
    "item_train_edge_index = torch.load('item_train_edges.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8ae1c7-e97f-4451-aa64-78a912282e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_train_edge_index = torch.load('user_train_edge_index.pt')\n",
    "user_train_edge_index.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4870137-a145-4d5d-bcb9-b8164659e650",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Test Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae5cb22-8739-4df0-90aa-722713dd9b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_test_edge_index = []\n",
    "item_test_edge_source = []\n",
    "item_test_edge_target = []\n",
    "seen_edges = set()\n",
    "\n",
    "file_path = 'test.txt'\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        values = list(map(int, line.strip().split()))\n",
    "        user = values[0]\n",
    "        items = values[1:]\n",
    "        user_edges = [(user, item) for item in items]\n",
    "        for i, item1 in enumerate(items):\n",
    "            for item2 in items[i+1:]:\n",
    "                if item1 < item2:\n",
    "                    if (item1,item2) not in seen_edges:\n",
    "                        seen_edges.add((item1,item2))\n",
    "                        item_test_edge_source.append(item1)\n",
    "                        item_test_edge_target.append(item2)\n",
    "                else:\n",
    "                    if (item2,item1) not in seen_edges:\n",
    "                        seen_edges.add((item2,item1))\n",
    "                        item_test_edge_source.append(item2)\n",
    "                        item_test_edge_target.append(item1)\n",
    "        user_test_edge_index.extend(user_edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658cabe5-aa3f-48fa-bff1-02cb3e16df48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_test_edge_index_np = np.array(user_test_edge_index, dtype=np.int64).T\n",
    "# user_test_edge_index = torch.tensor(user_test_edge_index_np, dtype=torch.long).contiguous()\n",
    "\n",
    "# item_test_edge_index = torch.tensor([item_test_edge_source, item_test_edge_target], dtype=torch.long)\n",
    "\n",
    "# torch.save(item_test_edge_index, 'item_test_edges.pt')\n",
    "item_test_edge_index = torch.load('item_test_edges.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29082b5f-c16c-4609-aba2-c8e47408900e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### graph dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587bcffe-5886-432c-93ef-d1261f6ea2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split between training message edges, training supervision edges, and validation edges\n",
    "\n",
    "# item_train_split = Data(edge_index=item_train_edge_index)\n",
    "# # user_train_split = Data(edge_index = user_train_edge_index)\n",
    "# item_train_message, item_train_super, item_val = train_test_split_edges(item_train_split, val_ratio = 0.1, test_ratio = 0.1)\n",
    "# # user_train_message_index, user_train_super_index, user_val_index = train_test_split_edges(user_train_split, val_ratio = 0.1, test_ratio = 0.1)\n",
    "# item_train_message_index = item_train_message.edge_index\n",
    "# item_train_super_index = item_train_super.edge_index\n",
    "# item_val_index = item_val.edge_index\n",
    "\n",
    "# num_edges = item_train_edge_index.size(1)\n",
    "# edge_indices = np.arange(num_edges)\n",
    "# np.random.shuffle(edge_indices)\n",
    "# split1_size = int(0.1 * num_edges)\n",
    "# split2_size = int(0.1 * num_edges)\n",
    "# split3_size = num_edges - split1_size - split2_size\n",
    "# split1_indices = edge_indices[:split1_size]\n",
    "# split2_indices = edge_indices[split1_size:split1_size + split2_size]\n",
    "# split3_indices = edge_indices[split1_size + split2_size:]\n",
    "\n",
    "# item_train_message_index = item_train_edge_index[:, split1_indices]\n",
    "# item_train_super_index = item_train_edge_index[:, split2_indices]\n",
    "# item_val_index = item_train_edge_index[:, split3_indices]\n",
    "\n",
    "# torch.save(item_train_message_index, 'item_train_message_index.pt')\n",
    "# torch.save(item_train_super_index, 'item_train_super_index.pt')\n",
    "# torch.save(item_val_index, 'item_val_index.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf4a2c2-047c-44dd-a270-e9b1f3120999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# item_train_super_index = torch.load('item_train_super_index.pt')\n",
    "# num_columns = item_train_super_index.shape[1]\n",
    "# num_indices_to_select = 150000\n",
    "# indices = np.random.choice(num_columns, size=num_indices_to_select, replace=False)\n",
    "# item_train_super_index_random = item_train_super_index[:, indices]\n",
    "# torch.save(item_train_super_index_random,'item_train_super_index_random.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93bfee9-9922-4767-adb1-9e6f830a0acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.load('X.pt')\n",
    "# item_test_edge_index = torch.load('item_test_edges.pt')\n",
    "# item_train_edge_index = torch.load('item_train_edges.pt')\n",
    "# item_train_message_index = torch.load('item_train_message_index.pt')\n",
    "# item_train_super_index = torch.load('item_train_super_index.pt')\n",
    "# item_val_index = torch.load('item_val_index.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb668886-bb17-4c10-ab3f-09fd22288393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_undirected\n",
    "# item_train_message_index = to_undirected(item_train_message_index)\n",
    "# item_train_super2_index = to_undirected(item_train_super_index)\n",
    "item_val_message_index = torch.cat((item_train_message_index, item_train_super_index), dim=1)\n",
    "item_val_2_index = to_undirected(item_val_index)\n",
    "item_test_message_index = torch.cat((item_val_message_index, item_val_2_index), dim=1)\n",
    "\n",
    "# user_val_message_index = torch.cat((user_train_message_index, user_train_super_index), dim=1)\n",
    "\n",
    "# torch.save(item_train_message_index, 'item_train_message_index.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afb8efd-9c94-4fac-9b21-260200334d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "item_test_edge_index = torch.load('item_test_edges.pt')\n",
    "num_columns = item_test_edge_index.shape[1]\n",
    "num_indices_to_select = 1000\n",
    "indices = np.random.choice(num_columns, size=num_indices_to_select, replace=False)\n",
    "item_test_edge_index_random = item_test_edge_index[:, indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6178c2-87c5-4246-a0e1-4be88434074b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_train_data = Data(x = X, edge_index=item_train_message_index, y = None, edge_label_index = item_train_super_index_random).to(device)\n",
    "# item_val_data = Data(x = X, edge_index=item_val_message_index, y = None, edge_label_index = item_val_index)\n",
    "item_test_data = Data(x = X, edge_index=item_test_message_index, y = None, edge_label_index = item_test_edge_index_random)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8cb984-79e7-4e21-ab95-1de789a9cbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of the nodes in training, validation and test data are\", item_train_data.num_nodes, item_val_data.num_nodes, item_test_data.num_nodes)\n",
    "print(\"Number of the edges in training, validation and test data are\", item_train_data.num_edges, item_val_data.num_edges, item_test_data.num_edges)\n",
    "print(\"Number of features:\", item_train_data.num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711970fc-f25f-41b3-b3c3-fe7e6d21730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "neighbor_loader = LinkNeighborLoader(item_train_data, num_neighbors=[2,2,2], edge_label_index = item_train_data.edge_label_index, neg_sampling_ratio = 1.0, batch_size=150, shuffle=True, subgraph_type = 'bidirectional')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e99e91-0c5c-41f3-beec-ed65b22ac733",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data = next(iter(neighbor_loader))\n",
    "print(sampled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9551f54a-2fe8-4d4a-929c-ac8a255369e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(neighbor_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edc11e9-738c-443e-bc92-1a3b9fee5875",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a5e939-cebe-4572-b0e2-fec79343bbd7",
   "metadata": {},
   "source": [
    "### Model with Attention Diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979d29d7-bf20-47a8-806b-6387a7cb8fb9",
   "metadata": {},
   "source": [
    "#### Model Architecture (Edge attributes not included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb16177b-c5cc-47f5-aeb2-368c95e414ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "\n",
    "class GATModel(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_heads = 8, dropout=0.3):\n",
    "        super(GATModel, self).__init__()\n",
    "        self.gat1 = GATv2Conv(in_channels, hidden_channels, heads=num_heads)\n",
    "        self.gat2 = GATv2Conv(hidden_channels * num_heads, hidden_channels, heads=num_heads)\n",
    "        self.gat3 = GATv2Conv(hidden_channels * num_heads, out_channels, heads=1)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        output = self.dropout(x) if self.training else x\n",
    "        output = self.gat1(output, edge_index)\n",
    "        output = self.relu(output)\n",
    "        output = self.dropout(output) if self.training else output\n",
    "        output = self.gat2(output, edge_index)\n",
    "        output = self.relu(output)\n",
    "        output = self.dropout(output) if self.training else output\n",
    "        output = self.gat3(output, edge_index)        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb414ff5-d958-46f5-b269-cbe78cb21f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GATModel(in_channels = item_train_data.num_features, hidden_channels=256, out_channels=128).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de2f925-b6f2-4b96-89ae-d2df161a4530",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.00005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb89e534-6aea-45c6-a3ad-35b16e4af138",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90962f22-2898-47ea-b1f5-244e5f1d1d54",
   "metadata": {},
   "source": [
    "##### Similarity (inner product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e66297-4256-45f0-98e0-956c83853e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(node_embs, edge_index):\n",
    "    result = (node_embs[edge_index[0], :] * node_embs[edge_index[1], :]).sum(dim=1, keepdim=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd477ffb-2793-4289-b3dc-d41f58288233",
   "metadata": {},
   "source": [
    "##### Negative Sampling (Random vs Hard Negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b94e3b-2602-40b4-92e7-b2db7463afbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import negative_sampling\n",
    "import networkx as nx\n",
    "\n",
    "## G_item_train = nx.Graph(user_train_edge_index)\n",
    "\n",
    "# def pos_sample(edges, nodes, num_samples, batch):\n",
    "\n",
    "\n",
    "def neg_sample(edges, nodes, num_samples, type = \"random\", batch = None):\n",
    "    if type == \"random\":\n",
    "        neg_edge_index = negative_sampling(edge_index = edges, num_nodes = nodes, num_neg_samples = num_samples)\n",
    "        return neg_edge_index\n",
    "    # if type == \"neg\":\n",
    "    #     random_nodes = random.sample(nodes, 500)\n",
    "    #     return random_nodes\n",
    "    # if type == \"hard\":\n",
    "    #     personalized_pagerank_all = []\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bf8157-a456-4fb6-859b-ce1f93acb5fc",
   "metadata": {},
   "source": [
    "##### Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312716fc-8d58-44c6-81e5-4e094a2f0a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn1 = torch.nn.BCEWithLogitsLoss()\n",
    "margin = 1.0\n",
    "loss_fn2 = torch.nn.MarginRankingLoss(margin=margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3846f7-5f33-45f1-876f-ec748b00bf52",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee98bc4-68ad-4159-bf5b-498745e89241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, loss_fn):\n",
    "    loss = 0\n",
    "    model.train()\n",
    "    for data in loader:\n",
    "        node_embs = model(data.x, data.edge_index)\n",
    "        # neg_edge_index = neg_sample(data.edge_index, data.num_nodes, data.edge_label_index.shape[1])\n",
    "        # edges = torch.cat((data.edge_label_index, neg_edge_index), dim = 1)\n",
    "        # edge_labels = torch.cat((torch.ones(data.edge_label_index.shape[1], 1), torch.zeros(data.edge_label_index.shape[1], 1)), dim = 0)\n",
    "        # similarity = compute_similarity(node_embs, edges)\n",
    "        # loss = loss_fn(similarity, edge_labels)\n",
    "        similarity = compute_similarity(node_embs, data.edge_label_index)\n",
    "        loss = loss_fn(similarity.to(device), data.edge_label.view(-1, 1).to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d701fd75-ac5c-4308-9212-edcdb84b459a",
   "metadata": {},
   "source": [
    "#### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317d2ced-5173-43bd-a1d4-f0bcde7088ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index)  # use `edge_index` to perform message passing\n",
    "    out = compute_similarity(out, data.edge_label_index).view(-1).sigmoid()  # use `edge_label_index` to compute the loss\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfd858e-fd21-4d90-907c-b17303958975",
   "metadata": {},
   "source": [
    "#### Model and Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b649d512-4ab5-4a3a-935d-543ebe870c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 7\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train(model, neighbor_loader, optimizer, loss_fn1)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "torch.save(model.state_dict(), 'saved_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3cd316-48ef-4e6f-81e1-26c2682eefa6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = GATModel(in_channels = item_train_data.num_features, hidden_channels=256, out_channels=128)\n",
    "state_dict = torch.load('saved_model.pth')\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4084d51-3d5a-43b8-871c-5b6a2c202785",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "neighbor_loader = LinkNeighborLoader(item_test_data, num_neighbors=[1,1,1], edge_label_index = item_test_data.edge_label_index, neg_sampling_ratio = 1.0, batch_size=50, shuffle=True, subgraph_type = 'induced')\n",
    "datas = next(iter(neighbor_loader))\n",
    "print(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c353556-a83a-4ad3-9761-9f18bf680616",
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = next(iter(neighbor_loader))\n",
    "datas.to(device)\n",
    "test_auc = test(model, datas)\n",
    "test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54be7a28-54c2-4ea3-ad2b-d83a14a933c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting function\n",
    "def plot_curves(curves):\n",
    "    epochs = range(1, len(curves[\"train\"]) + 1)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Plot training loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, curves[\"train\"], label='Training Loss')\n",
    "    plt.title('Training Loss over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xticks(epochs)\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot validation and test metrics\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, curves[\"valid\"], label='Validation Metric', color='orange')\n",
    "    plt.plot(epochs, curves[\"test\"], label='Test Metric', color='green')\n",
    "    plt.title('Validation and Test Metrics over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Metric')\n",
    "    plt.xticks(epochs)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# curves\n",
    "train_curve = []\n",
    "valid_curve = []\n",
    "test_curve = []\n",
    "\n",
    "# Running MODEL\n",
    "epochs = 10\n",
    "\n",
    "best_val_auc = final_test_auc = 0\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train(model, item_train_data, optimizer, loss_fn1)\n",
    "    valid_auc = test(model, item_val_data)\n",
    "    test_auc = test(model, item_test_data)\n",
    "    if valid_auc > best_val_auc:\n",
    "        best_val_auc = valid_auc\n",
    "        final_test_auc = test_auc\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {valid_auc:.4f}, Test: {test_auc:.4f}')\n",
    "    train_curve.append(loss)\n",
    "    valid_curve.append(valid_auc)\n",
    "    test_curve.append(test_auc)\n",
    "    \n",
    "curves = {\"train\": train_curve, \"valid\": valid_curve, \"test\": test_curve}\n",
    "print('Best Validation Metric: {}'.format(best_val_auc))\n",
    "print('Test Metric: {}'.format(final_test_auc))\n",
    "\n",
    "# plot\n",
    "plot_curves(curves)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b76557e-478d-4c0c-b984-970c9b2806de",
   "metadata": {},
   "source": [
    "### Model with Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1c82a3-cea1-4c63-a056-778fe90bd7d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Message Passing for User Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b275108-a1ca-4ddb-b45f-6a56f593692e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def randUser(numUsers):\n",
    "    random_numbers = [random.randint(0, numUsers - 1) for _ in range(100)]\n",
    "    tensor_users = torch.tensor(random_numbers)\n",
    "    return tensor_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b59b3a-67fb-4c39-a030-bf8b5d6f53c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_batch = randUser(52642)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f782f2b3-0913-4fe8-bb1d-160f99de3b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_train_edge_index = torch.load('item_train_message_index.pt')\n",
    "X = torch.load('X.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36134120-44bb-4461-9f52-052a35d41649",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_nodes = []\n",
    "target_nodes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f9e02a-b9da-4349-a581-864c9a979fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "import pickle\n",
    "file_path1 = 'user_train_message.pkl'\n",
    "file_path2 = 'user_train_super.pkl'\n",
    "file_path3 = 'user_train_neg.pkl'\n",
    "user_train_message = defaultdict(list)\n",
    "user_train_supervision = defaultdict(list)\n",
    "user_train_neg = defaultdict(list)\n",
    "\n",
    "file_path = 'train.txt'\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        values = list(map(int, line.strip().split()))\n",
    "        user = values[0]\n",
    "        items = values[1:]\n",
    "        size_first_list = int(len(items) * 0.8)\n",
    "        size_second_list = len(items) - size_first_list\n",
    "        message_list = random.sample(items, size_first_list)\n",
    "        super_list = list(set(items) - set(message_list))\n",
    "        user_train_message[user] = message_list\n",
    "        user_train_supervision[user] = super_list\n",
    "        user_train_neg[user] = random.sample(range(91599), size_second_list)\n",
    "with open(file_path1, 'wb') as file:\n",
    "    pickle.dump(user_train_message, file)\n",
    "with open(file_path2, 'wb') as file:\n",
    "    pickle.dump(user_train_supervision, file)\n",
    "with open(file_path3, 'wb') as file:\n",
    "    pickle.dump(user_train_neg, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f74d333-7556-4393-aed6-06fcbe787c9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(user_train_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a10a020-f040-4280-badd-60cb57d5023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import NeighborLoader\n",
    "item_train_data = Data(x = X, edge_index=item_train_edge_index, y = None).to(device)\n",
    "loader = NeighborLoader(\n",
    "    item_train_data,\n",
    "    num_neighbors=[8] * 3,\n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8380df-22b2-439c-b371-51a531fa400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(loader))\n",
    "sampled_data = next(iter(loader))\n",
    "print(sampled_data)\n",
    "# print(sampled_data.n_id)\n",
    "# print(sampled_data.input_id)\n",
    "print(sampled_data.n_id[sampled_data.input_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7ab735-d4fa-4bd0-b9e4-cecb89a76aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.nn import knn_graph\n",
    "# edge_index_2nd_order = knn_graph(item_data.x, 10, loop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8394a527-1110-4208-b918-77f4710136a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GATModel(in_channels = X.shape[1], hidden_channels=256, out_channels=128).to(device)\n",
    "state_dict = torch.load('saved_model.pth')\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2d34db-dbb9-421d-b5fd-14dc6448ab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_embeddings = torch.zeros((91599, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a03860-f6f3-411e-b62c-be0c4ed37cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(loader):\n",
    "        item_embed = model(data.x, data.edge_index)\n",
    "        maps = defaultdict(int)\n",
    "        for i in range(len(data.n_id)):\n",
    "            maps[data.n_id[i]] = i\n",
    "        map_back = []\n",
    "        for i in range(len(data.input_id)):\n",
    "            map_back.append(maps[data.input_id])\n",
    "        spec_embed = item_embed[map_back]\n",
    "        final_embeddings[data.input_id] = spec_embed.to('cpu')\n",
    "        del item_embed\n",
    "        print(batch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a81c932-01a8-48b6-acf7-9deddfdaafdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(final_embeddings, 'final_embeddings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf10ae6-8fac-4942-b273-8453953a81ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_embeddings = torch.load('final_embeddings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ceb2ae-d650-4d8f-b2d1-1d85c3dd7f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "source_nodes = []\n",
    "target_nodes = []\n",
    "file_path1 = 'user_train_message.pkl'\n",
    "with open(file_path1, 'rb') as file:\n",
    "    loaded_dict = pickle.load(file)\n",
    "for user in loaded_dict:\n",
    "    items = loaded_dict[user]\n",
    "    for item in items:\n",
    "        source_nodes.append(user)\n",
    "        target_nodes.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b066724-7b77-48d9-86db-63b3126d4212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "user_train_message_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "num_users = 52643\n",
    "num_items = 91599\n",
    "adj = torch.zeros((num_users, num_items))\n",
    "adj[user_train_message_index[0], user_train_message_index[1]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc07d3ec-2580-4b7b-a4d7-7a79f0e714eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e61e300-c19e-472e-b1b7-e2e3e50174e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_degree = adj.sum(dim = 1, keepdim = True)\n",
    "item_degree = adj.sum(dim = 0, keepdim = True)\n",
    "user_degree = torch.where(user_degree == 0, torch.tensor(1), user_degree)\n",
    "item_degree = torch.where(item_degree == 0, torch.tensor(1), item_degree)\n",
    "adj_norm = torch.divide(torch.divide(adj, torch.sqrt(user_degree)),torch.sqrt(item_degree))\n",
    "# adj_norm_3 = torch.matmul(torch.matmul(adj_norm, adj_norm.t()),adj_norm)\n",
    "# adj_norm_5 = torch.matmul(torch.matmul(adj_norm_3, adj_nom.t()),adj_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ba9d5c-96f3-42b8-bee3-318e7b54a290",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(adj_norm, 'adj_norm.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba48d62-e867-4a46-9903-6d93f9317992",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeddings = torch.matmul(adj_norm, item_embeddings)\n",
    "# user_embeddings_3 = torch.matmul(adj_norm_3, item_embeddings)\n",
    "# user_embeddings_5 = torch.matmul(adj_norm_5, item_embeddings)\n",
    "# final_user_embedding = torch.cat((user_embeddings, user_embeddings_3), dim = 1)\n",
    "torch.save(user_embeddings, 'final_user_embedding.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e882adb-8273-4ad2-b17b-4bdf9e4725b7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Model Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb7b029-bce6-4c82-ae48-8dedae941c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_path1 = 'user_train_super.pkl'\n",
    "with open(file_path1, 'rb') as file:\n",
    "    train_pos = pickle.load(file)\n",
    "file_path2 = 'user_train_neg.pkl'\n",
    "with open(file_path2, 'rb') as file:\n",
    "    train_neg = pickle.load(file)\n",
    "user_embeddings = torch.load('final_user_embedding.pt')\n",
    "item_embeddings = torch.load('final_embeddings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf483354-eb74-41bf-8bab-0611a41ff404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class LinkPredict(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels = 256, out_channels = 1):\n",
    "        super(LinkPredict, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(in_channels, hidden_channels)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e37093-57a1-424d-a8c3-316739918b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinkPredict(in_channels = user_embeddings.shape[1] * 2).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903ed1ac-73df-49e8-af2d-1c43df325ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.0025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0a8c7a-8363-462d-8042-0d394318675d",
   "metadata": {},
   "source": [
    "##### Loss Function (Bayesian Personalized Ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd57edc-6d61-456d-b6ec-debc6918763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.loss import _Loss\n",
    "class BPRLoss(_Loss):\n",
    "    def __init__(self, lambda_reg: float = 0.0001, **kwargs):\n",
    "        super().__init__(None, None, \"sum\", **kwargs)\n",
    "        self.lambda_reg = lambda_reg\n",
    "    def forward(self, positives, negatives, parameters, num_users):\n",
    "        log_prob = torch.nn.functional.logsigmoid(positives - negatives).mean()\n",
    "        # reg = 0\n",
    "        # flat_parameters = torch.cat([p.view(-1) for p in parameters])\n",
    "        # if self.lambda_reg != 0:\n",
    "        #     reg = self.lambda_reg * flat_parameters.norm(p = 2).pow(2)\n",
    "        #     reg = reg/positives.size(0)\n",
    "        return -log_prob # + reg/num_users\n",
    "loss_fn = BPRLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a916fa17-65b7-4b4c-b9fd-8aea24946887",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08af667-c499-41fa-9b89-1f361ba7453d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, users, optimizer, user_embedding, item_embedding, train_pos, train_neg, loss_fn):\n",
    "    loss = 0\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    num_users = len(users)\n",
    "    for user in users:\n",
    "        pos_embed = item_embeddings[train_pos[user]]\n",
    "        neg_embed = item_embeddings[train_neg[user]]\n",
    "        user_embed = user_embedding[user, :]\n",
    "        pos_embeds = torch.cat((user_embed.expand(pos_embed.size(0), -1), pos_embed), dim = 1)\n",
    "        neg_embeds = torch.cat((user_embed.expand(neg_embed.size(0), -1), neg_embed), dim = 1)       \n",
    "        pos_values = model(pos_embeds.to(device))\n",
    "        neg_values = model(neg_embeds.to(device))\n",
    "\n",
    "        loss += -(torch.nn.functional.logsigmoid(pos_values - neg_values).mean())\n",
    "        # loss += loss_fn(pos_values, neg_values, list(model.parameters()), num_users).to(device)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20c35db-7517-4d47-9502-4cb1b64e4784",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b4d649-9c59-4799-bb6f-588c52ed5968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def test(model, data):\n",
    "#     model.eval()\n",
    "#     out = model(data.x, data.edge_index)  # use `edge_index` to perform message passing\n",
    "#     out = compute_similarity(out, data.edge_label_index).view(-1).sigmoid()  # use `edge_label_index` to compute the loss\n",
    "#     return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf65bd3-041b-4af8-996b-29131e29f904",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Model Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b52030b-b9ae-473e-9030-48dda2f1c847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running MODEL\n",
    "epochs = 10\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train(model, list(range(52643)), optimizer, user_embeddings, item_embeddings, train_pos, train_neg, loss_fn)\n",
    "    # valid_auc = test(model, val_data)\n",
    "    # test_auc = test(model, test_data)\n",
    "    # if valid_auc > best_val_auc:\n",
    "    #     best_val_auc = valid_auc\n",
    "    #     final_test_auc = test_auc\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "    # train_curve.append(loss)\n",
    "    # valid_curve.append(valid_auc)\n",
    "    # test_curve.append(test_auc)\n",
    "    \n",
    "# curves = {\"train\": train_curve, \"valid\": valid_curve, \"test\": test_curve}\n",
    "# print('Best Validation Metric: {}'.format(best_val_auc)\n",
    "# print('Test Metric: {}'.format(final_test_auc)\n",
    "\n",
    "# # plot\n",
    "# plot_curves(curves)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
